<!--VarStream
title=Designing HTTP REST APIs with NodeJS
description=Designing good HTTP services is still a hard thing despite the many\
 tools you can find to make them with NodeJS. I'm trying to define a formal\
 approach to achitecture them by embracing the HTTP protocol nature and the\
 RESTful principles.
shortTitle=HTTP API Design
shortDesc=See how i design HTTP APIs with NodeJS
published=2016-11-12T09:50:52.000Z
lang=en
location=US
keywords.+=API
keywords.+=REST
keywords.+=HTTP
categories.+=.*
disqus=true
draft=false
-->

<h2>Designing HTTP REST APIs</h2>
<p>
  You may have read my <a href="no_more_middlewares.html">no more middlewares</a>
  blog post and wonder what led me to this mindset about middlewares. I would
  like to explain here why i think that Express (but also its contesters like
  Hapi or Restify) are not that good when it comes to build REST APIs by
  explaining the challenges of designing a HTTP REST API and how i'm trying to
  do it.
</p>
<p><strong>
  TL.DR. HTTP/REST API complexity does not worth creating a framework.
</strong></p>
<h3>Design considerations</h3>
<h4>The server: A state dealer</h4>
<p>
  <strong>An HTTP server is a gateway allowing to read/write states</strong>.
  Those states may sit in a database or a file storage system. An HTTP
  transaction allows you to retrieve those states (with the OPTIONS/GET verbs)
  and to change them (with POST/PUT/PATCH/DELETE ones). The states are located
  with the help of URIs, behind an URI one or more states can be involved.
</p>
<p>
  Building an HTTP server mainly consist in defining the states you want to
  keep and where you want to store them. Once defined, you'll have to
  define the rules determining what happens when a state changes.
</p>
<h4>Retrieving states</h4>
<p>
  This is the easy part. Retrieving states is done with simple GET requests
  (you may also have heard about the
  <a href="https://datatracker.ietf.org/doc/rfc5323/">SEARCH method</a>).
</p>
<p>
  States are rarely provided as is from their storage. They are often
  transformed into a representation, this is known as
  <a href="https://fr.wikipedia.org/wiki/Representational_state_transfer">representationnal
  state transfert (REST)</a>.
</p>
<p>
  It is worth noting a resource representation can be seen as a pure function:<br />
  <code>response = f(request, ...states)</code><br />
  Answering a GET HTTP request is as simple as decoding the request, retrieve
  the involved states and build a representation of the actual resource.
</p>
<p>
  The beauty of an HTTP server is that states are more concepts than real data.
  The state of an unexisting resource is that it doesn't exists.
</p>
<h4>Changing states</h4>
<p>
  When using the PUT/POST/PATCH methods in an HTTP request, we typically
  provide some content with our HTTP request that describes the changes we
  want to perform.
</p>
<p>
  For DELETE ones, it is a bit simpler. We are only providing the name (its URI
  for instance) of the resource we want to delete.
</p>
<p>
  Handling state changes is a bit harder. Indeed, i usually split it into two
  phases:
</p>
<h5>Acknowledgment</h5>
<p>
  This is when the status code and the HTTP headers are sent to the client.
  When a server acknowlegde a resource change, the implicit contract is that
  any other request involving its underlying states will take those changes
  in count.
</p>
<p>
  If someone upload a file by performing a <code>PUT /fs/myfile</code> request,
  you can send response headers only when it is guaranteed that a
  <code>GET /fs/myfile</code> will successfully complete. This is the
  transactionnal part of an HTTP server.
</p>
<p>
  This might not be true for large systems on short time frames or for two
  clients based on two very distant regions but those trade offs doesn't affect
  an API design in most cases.
</p>
<p>
  The new states of the resource can be expressed as a pure function of the
  HTTP request:<br />
  <code>states = f(request)</code>
</p>
<h5>Contractual computations</h5>
<p>
  Then, you will probably need to perform some computations based on those
  changes. Things like sending an email, processing an image, syncing with
  third parties etc...
</p>
<p>
  Those post HTTP transaction computes shouldn't change the server state. But since you
  already answered to the HTTP client everything went fine, you should guarantee
  those computes will always happen.
</p>
<p>
  The best way to handle this is using a message queueing system like RabbitMQ
  and having some workers computing those post changes triggers. Once your
  state change event is in the queue, you can acknowledge the request and be
  sure expected computations will be done.
</p>
<p>
  The big part in designing those triggers is to ensure the acknowledged data
  is valid and won't suffer of a lack of information. Content validation is a
  a major concern here.
</p>
<p>
  You also have to deal with the possible outage of the various systems your
  triggers rely on. This is why i mostly try to handle it with idempotent calls.
  That way, workers can retry computing an event until it eventually works.
  This is not always possible though, by example for sending e-mails.
</p>
<h4>A stateless protocol</h4>
<p>
  Despite the fact an HTTP server is full of states, the interesting thing to
  notice about HTTP is that it is a stateless protocol. HTTP transactions are
  fully independent from each others.
</p>
<p>
  Since a resource representation is a pure function returning a response from
  a request and its involved states. You can see the
  HTTP GET request/response relation as a pure function until its underlying
  states change:<br />
  <code>response = f(request)</code>
</p>
<p>
  This is where the stateless nature of HTTP helps designing APIs in a simple
  manner. For the same state and the same request, you'll always get the same
  response (it is slightly different for POST calls, this is why i avoid using it
  in most cases).
</p>
<p>
  Indeed, OPTIONS, GET, PUT and DELETE requests are known as idempotent. PATCH
  and POST ones are not. I avoid using POST but i often create PATCH endpoints while
  ensuring mines are idempotent (this is while i strongly discourage you using
  <a href="http://jsonpatch.com/">JSON patch</a> since its current implementation
  forbids doing idempotent patches).
</p>
<p>
  Another interesting property of HTTP is that since a PUT/PATCH and DELETE
  request contains the full recipe to build the final state of the resource its
  changing, even if the initial resource state is different, the final state
  will be the same for two identical requests.
</p>
<p>
  So we end up with a crystal clear vison of modificative and idempotent HTTP
  requests<br />
  <code>states = f(request) response = f(request, ...states))</code>
</p>
<p>
  All in all, designing a REST API is mainly about describing very simple
  asynchronous workflows into a few key steps were simple function composition
  can easily do the job.
</p>
<h4>Keeping states consistent</h4>
<p>
  This is impossible. At least with high performances and availability. Indeed,
  to ensure a coherent global state, you have to queue state changes (at least
  those depending on other states). This is typically the relationnal databases
  strategy.
</p>
<p>
  Suscribing to this strategy involves accepting to refuse some state changes.
  Indeed, imagine that a user wants to change the price of a product. The web
  application would first retrieve it and prompt a form allowing him to make
  that change.
</p>
<p>
  Another user could have deleted this product so that when the user will
  validate the form, the product will no longer exists. Most server side
  implementation will simply return an error saying the product no longer
  exists and the user will simply loose its changes. But another implementation
  could simply "revive" the product or change the archived product price.
</p>
<p>
  But what about two users changing the product price at the same time? Should
  we refuse edition and warn the user? Should we compute the difference between
  the two concurrent changes? Or maybe prompt the user to do so (like git do
  for developpers).
</p>
<p>
  The final choice strongly depends on a lot of factors and, in fact, the only
  thing i'm sure about is that you <strong>can't fully automate those
  choices</strong>.
</p>
<p>
  Each server endpoint has its own constraint, its own reason to exist and needs
  you to implement its own, original workflow based on your business contraints.
</p>
<h3>Coding REST APIs with NodeJS</h3>
<p>
  So, given all those interesting aspects of designing a REST API, why would we
  use things like <a href="https://en.wikipedia.org/wiki/Middleware">middlewares</a>,
  <a href="https://en.wikipedia.org/wiki/Object-relational_mapping">ORM</a> or
  that shinny new framework plugin system?
</p>
<p>
  In my quest to find the holy grail of the REST API frameworks, i ended up
  building my own: <a href="https://github.com/nfroidure/whook">Whook</a>.
</p>
<p style="text-align: center;">
  <img src="http://static.fjcdn.com/pictures/Monty_4501e1_493629.jpg"
    alt="Double Face Palm: Because you forgot to get in the wooden rabbit" />
</p>
<p>
  Guess what, i <strong>failed</strong>. I thought <strong>existing framework
  were bad while the framework idea itself was bad</strong>. Don't get me wrong,
  i don't say that all HTTP frameworks you can find out on NPM should not be used.
</p>
<p>
  In fact, i managed to use ExpressJS successfully many times and i think it can
  still be useful for quickly prototyping NodeJS backends. But the thruth is
  that i spent most of my time reducing the Express features i used overtime.
</p>
<p>
  Currently, i'm leaving behind the last Express pieces by using simple libraries
  providing pure functions most of the time.
</p>
<p>
  In my quest to design great REST APIs with NodeJS, i finally ended up with
  a few simple patterns and principles i want to share with you:
</p>
<h4>Process lifetime</h4>
<p>
  As we saw above, an HTTP server is constantly dealing with external states.
  Those states can be database servers, key/value stores, other REST APIs, the
  current time etc...
</p>
<p>
  This has a lot to do with the process lifetime. Indeed, before accepting
  connections we must ensure the database connection is correctly set.
  Also, when shutting down a server, we must ensure that every requests were
  fulfilled.
</p>
<p>
  For those concerns, i created
  <a href="https://github.com/nfroidure/knifecycle">Knifecyle</a>, a
  dependency injection system inspired by the Angular one. It is pretty simple
  but allows me maintaining states services decoupled from the actual server
  endpoints code.
</p>
<p>
  It also allow me to tied an endpoint with its required services and only
  those ones. That way i can easily reuse an endpoint in another project while
  being sure all its needed services are available.
</p>
<p>
  Since it injects services thanks to a simple object, it has no footprint on the
  enpoint handlers. That way i can reuse it in any other application.
</p>
<h4>Documentation driven API</h4>
<p>
  There is nothing worse than having no documentation. The first building block
  of an endpoint should be its documentation.
</p>
<p>
  When creating endpoints, i begin by writing a module describing its inputs
  and outputs. It is not necessarily a Swagger definition but an
  <a href="https://github.com/nfroidure/TripStory/blob/master/backend/app/trips/trips.metadata.js">intermediate
  description that could produce a Swagger definition file</a>.
</p>
<p>
  That way we avoid documentation drifting. Never rely on a human when it comes
  to documenting anything.
</p>
<h4>Single enpoint routing</h4>
<p>
  Since an HTTP endpoint is a unique and original workflow you have to
  implement, i prefer using only one handler per endpoint and use async functions
  composition in a single file that describes this workflow.
</p>
<p>
  I recently released <a href="https://github.com/nfroidure/siso">Siso</a>
  that allows to create a simple routing function without having to rely on a
  complete framework.
</p>
<h4>Workflow based endpoint handlers</h4>
<p>
  For each endpoints, i create an unique workflow based on a promise chain
  whose stages basically are:
</p>
<ul>
  <li>
    decode/transform/validate the request with function composition;
  </li>
  <li>
    perform state changes with the help of injected services;
  </li>
  <li>
    acknowledge changes;
  </li>
  <li>
    build the response.
  </li>
</ul>
<p>
  In consequence, my code is organized in a simple manner that map the above
  workflow structure:
</p>
<ul>
  <li>
    metada: configuration describing routes, their input/ouput and any other
    information allowing to generate a documentation;
  </li>
  <li>
    validators: pure functions that validate datas or throw errors. I like using
    JSONSchema to create them since it can be used to produce a Swagger file;
  </li>
  <li>
    transformers: pure re-entrant functions that transform states to
    representations and representations to states;
  </li>
  <li>
    services: injected code to deal with application states;
  </li>
  <li>
    helpers: pure functions that factorize redundant workflow stages (parsing
    payloads according to the content type header, rights management etc...).
  </li>
</ul>
<p>
  I take care to avoid coupling endpoint worflows with route declaration in
  order to keep my workflows the purest possible. You can see those principles
  in action into the <a href="https://github.com/nfroidure/TripStory">Trip Story</a>
  project we made for an hackathon (worth noting it till uses Express ;) ). It
  is a step backward though but i promise i'll soon release a new side project
  with all those principles in action.
</p>
<h3>As a conclusion</h3>
<p>
  I'd like to end this post by a call to the JavaScript community: please,
  release purely functionnal modules whenever possible. Projects like
  <a href="https://github.com/jshttp">jshttp</a> are nice but could be much
  more useful with a more functionnal approach.
</p>
<p>
  We should stop assuming a <code>req</code>, <code>res</code> or <code>app</code>
  object and instead create pure function. As an example, the
  <a href="https://github.com/jshttp/vary">vary</a> project should take the
  current Vary header value in and return its new value instead of requesting
  a <code>res</code> object. It would avoid all
  <a href="https://github.com/jshttp/vary/blob/master/index.js#L108-L123">those
   unnecessary checks</a> while making it usable for more use cases.
</p>
<h4>A step toward universal APIs</h4>
<p>
  With the raise of service workers, the need to reuse backend code in the
  browser will be crucial. Adopting a more functionnal approach will allow to
  take best advantages of the existing codebases.
</p>
<p>
  It will be very hard, maybe impossible, to reuse your ORM code into the
  browser, neither to make predictive HTTP responses in a service worker
  with a codebase relying on middlewares or your preferred framework plugin
  system.
</p>
<p>
  I hope you find this post more clear and whish it will help improve the way we
  are creating REST web services with NodeJS.
</p>
